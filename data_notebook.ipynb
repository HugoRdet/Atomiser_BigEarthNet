{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e28fc5-b768-412c-8e0a-91aece41507a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1103b3530>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from training.perceiver import*\n",
    "from training.utils import*\n",
    "from training.losses import*\n",
    "from training.VIT import*\n",
    "from training.ResNet import*\n",
    "from collections import defaultdict\n",
    "from training import*\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import einops as einops\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Reduce\n",
    "from pytorch_lightning.profilers import AdvancedProfiler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from configilm import util\n",
    "util.MESSAGE_LEVEL = util.MessageLevel.INFO  # use INFO to see all messages\n",
    "\n",
    "\n",
    "from configilm.extra.DataSets import BENv2_DataSet\n",
    "from configilm.extra.DataModules import BENv2_DataModule\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7188037a-09cf-4063-a849-c4f9c5ddb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cc97c1-2090-4da3-a929-18ff5737e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_BENv2(mode=None,max_len=None):\n",
    "    dico_paths={\"images_lmdb\":\"data/Encoded-BigEarthNet/\",\n",
    "    \"metadata_parquet\":\"data/Encoded-BigEarthNet/metadata.parquet\",\n",
    "    \"metadata_snow_cloud_parquet\":\"data/Encoded-BigEarthNet/metadata_for_patches_with_snow_cloud_or_shadow.parquet\"}\n",
    "\n",
    "    df=open_parquet(dico_paths[\"metadata_parquet\"])\n",
    "\n",
    "    if max_len!=None:\n",
    "        return BENv2_DataSet.BENv2DataSet(data_dirs=dico_paths, img_size=(14, 120, 120),split=mode,max_len=max_len),df\n",
    "\n",
    "    \n",
    "    return BENv2_DataSet.BENv2DataSet(data_dirs=dico_paths, img_size=(14, 120, 120),split=mode),df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc046e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(name,trans_conf,trans_tokens,sizes=(2,2,2),max_len=None,max_len_h5=-1):\n",
    "\n",
    "   \n",
    "    mode=\"train\"\n",
    "    ds,df=prepare_BENv2(max_len=max_len)\n",
    "\n",
    "    idxs,_=get_tiny_dataset(ds,df,MAX_IDs=sizes[0],mode=mode)\n",
    "    #idxs=None\n",
    "    stats=create_dataset(idxs, ds,df, name=name, mode=mode, trans_config=trans_conf,trans_tokens=trans_tokens,stats=None,max_len=max_len_h5)\n",
    "\n",
    "    mode=\"validation\"\n",
    "    ds,df=prepare_BENv2(max_len=max_len)\n",
    "    \n",
    "    \n",
    "    idxs,_=get_tiny_dataset(ds,df,MAX_IDs=sizes[1],mode=mode)\n",
    "    #idxs=None\n",
    "    create_dataset(idxs, ds,df, name=name, mode=mode,trans_config=trans_conf,trans_tokens=trans_tokens,stats=stats,max_len=max_len_h5)\n",
    "\n",
    "    mode=\"test\"\n",
    "    ds,_=prepare_BENv2(max_len=max_len)\n",
    "    idxs,_=get_tiny_dataset(ds,df,MAX_IDs=sizes[2],mode=mode)\n",
    "    #idxs=None\n",
    "    create_dataset(idxs, ds,df, name=name, mode=mode,trans_config=trans_conf,trans_tokens=trans_tokens,stats=stats,max_len=max_len_h5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebd737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[INFO]    Loading BEN data for None...\u001b[0m\n",
      "\u001b[96m[INFO]        480038 patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]        480038 pre-filtered patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]        480038 filtered patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]    Merged metadata with snow/cloud metadata\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded 549488 labels\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded 549488 keys\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded mapping created\u001b[0m\n",
      "\u001b[96m[INFO]    Opening LMDB environment ...\u001b[0m\n",
      "summary dico stats\n",
      "{18: 7000, 12: 7000, 8: 7000, 6: 7000, 1: 7000, 11: 7000, 15: 7000, 9: 7000, 14: 6767, 13: 5589, 3: 7000, 16: 7000, 17: 7000, 0: 7000, 5: 7000, 4: 679, 10: 7000, 7: 6075, 2: 694}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m modalities_trans= modalities_transformations_config(configs_dataset,name_config=\u001b[33m\"\u001b[39m\u001b[33mregular\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m test_conf= transformations_config(bands_yaml,config_dico)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mcreate_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mregular\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodalities_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrans_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43msizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m7000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m7000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m7000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_len_h5\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcreate_datasets\u001b[39m\u001b[34m(name, trans_conf, trans_tokens, sizes, max_len, max_len_h5)\u001b[39m\n\u001b[32m      7\u001b[39m idxs,_=get_tiny_dataset(ds,df,MAX_IDs=sizes[\u001b[32m0\u001b[39m],mode=mode)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#idxs=None\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m stats=\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43midxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrans_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrans_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrans_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_len_h5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m mode=\u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m ds,df=prepare_BENv2(max_len=max_len)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Atomiser_BigEarthNet/training/utils/utils_dataset_h5.py:157\u001b[39m, in \u001b[36mcreate_dataset\u001b[39m\u001b[34m(dico_idxs, ds, df, name, mode, trans_config, trans_tokens, stats, max_len)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_dataset\u001b[39m(dico_idxs, ds,df, name=\u001b[33m\"\u001b[39m\u001b[33mtiny\u001b[39m\u001b[33m\"\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m,trans_config=\u001b[38;5;28;01mNone\u001b[39;00m,trans_tokens=\u001b[38;5;28;01mNone\u001b[39;00m, stats=\u001b[38;5;28;01mNone\u001b[39;00m,max_len=-\u001b[32m1\u001b[39m):\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dico_idxs!=\u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_dataset_dico\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdico_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrans_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrans_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrans_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# 1) Clean up any existing file\u001b[39;00m\n\u001b[32m    162\u001b[39m     h5_path = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m./data/Tiny_BigEarthNet/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.h5\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Atomiser_BigEarthNet/training/utils/utils_dataset_h5.py:322\u001b[39m, in \u001b[36mcreate_dataset_dico\u001b[39m\u001b[34m(dico_idxs, ds, name, mode, trans_config, trans_tokens, stats)\u001b[39m\n\u001b[32m    316\u001b[39m # Apply per-channel normalization\n\u001b[32m    317\u001b[39m # normalized_value = (value - mean[channel]) / std[channel]\n\u001b[32m    318\u001b[39m img = (img - means) / stds\n\u001b[32m    320\u001b[39m #shape_train=get_img_shape_trans(img,elem_id,trans_config,trans_tokens,mode=mode,modality_mode=\"train\")\n\u001b[32m    321\u001b[39m #shape_validation=get_img_shape_trans(img,elem_id,trans_config,trans_tokens,mode=mode,modality_mode=\"validation\")\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m #shape_test=get_img_shape_trans(img,elem_id,trans_config,trans_tokens,mode=mode,modality_mode=\"test\")\n\u001b[32m    323\u001b[39m \n\u001b[32m    324\u001b[39m \n\u001b[32m    325\u001b[39m \n\u001b[32m    326\u001b[39m \n\u001b[32m    327\u001b[39m # Convert back to numpy to store in HDF5\n\u001b[32m    328\u001b[39m db.create_dataset(f'image_{cpt_train}', data=img.numpy().astype(np.float16))\n\u001b[32m    329\u001b[39m db.create_dataset(f'label_{cpt_train}', data=label.numpy().astype(int))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Atomiser_BigEarthNet/training/utils/utils_dataset_h5.py:254\u001b[39m, in \u001b[36mget_img_shape_trans\u001b[39m\u001b[34m(img, elem_id, trans_config, trans_tokens, mode, modality_mode)\u001b[39m\n\u001b[32m    250\u001b[39m tmp_img=img[\u001b[32m2\u001b[39m:,:,:]\n\u001b[32m    253\u001b[39m tmp_mask=torch.ones(tmp_img.shape)\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m tmp_img,tmp_mask=\u001b[43mtrans_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_transformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmp_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melem_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodality_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodality_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m tmp_img,tmp_mask=trans_tokens.process_data(tmp_img.unsqueeze(\u001b[32m0\u001b[39m),tmp_mask.unsqueeze(\u001b[32m0\u001b[39m))\n\u001b[32m    256\u001b[39m tmp_img=tmp_img.squeeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Atomiser_BigEarthNet/training/utils/utils_modalities_transformation.py:205\u001b[39m, in \u001b[36mmodalities_transformations_config.apply_transformations\u001b[39m\u001b[34m(self, img, mask, idx, mode, modality_mode)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mresolution\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m transfos:\n\u001b[32m    204\u001b[39m     new_resolution=\u001b[38;5;28mint\u001b[39m(img.shape[\u001b[32m1\u001b[39m]*\u001b[38;5;28mfloat\u001b[39m(transfos[\u001b[33m\"\u001b[39m\u001b[33mresolution\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     img,mask=\u001b[43mchange_resolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_resolution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mremove\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;129;01min\u001b[39;00m transfos:\n\u001b[32m    208\u001b[39m     img,mask=remove_bands(img,mask,\u001b[38;5;28mself\u001b[39m.get_channels_from_froup(transfos[\u001b[33m\"\u001b[39m\u001b[33mremove\u001b[39m\u001b[33m\"\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Atomiser_BigEarthNet/training/utils/image_utils.py:92\u001b[39m, in \u001b[36mchange_resolution\u001b[39m\u001b[34m(img, mask, target_size, keep_res)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchange_resolution\u001b[39m(img,mask,target_size,keep_res=\u001b[38;5;28;01mTrue\u001b[39;00m):   \n\u001b[32m     91\u001b[39m     orig_size=img.shape[\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     img=\u001b[43mv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m(img)\n\u001b[32m     93\u001b[39m     img=v2.Resize(size=orig_size)(img)\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img,mask\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/torchvision/transforms/v2/_geometry.py:140\u001b[39m, in \u001b[36mResize.__init__\u001b[39m\u001b[34m(self, size, interpolation, max_size, antialias)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    135\u001b[39m     size: Union[\u001b[38;5;28mint\u001b[39m, Sequence[\u001b[38;5;28mint\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m     antialias: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    139\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m    143\u001b[39m         size = [size]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/torchvision/transforms/v2/_transform.py:30\u001b[39m, in \u001b[36mTransform.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[43m_log_api_usage_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/torchvision/utils.py:627\u001b[39m, in \u001b[36m_log_api_usage_once\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    623\u001b[39m         colors = [\u001b[38;5;28mtuple\u001b[39m(v / \u001b[32m255\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m color) \u001b[38;5;28;01mfor\u001b[39;00m color \u001b[38;5;129;01min\u001b[39;00m colors]  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m    624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m colors  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_log_api_usage_once\u001b[39m(obj: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    629\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[33;03m    Logs API usage(module and name) within an organization.\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[33;03m    In a large ecosystem, it's often useful to track the PyTorch and\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    643\u001b[39m \u001b[33;03m        obj (class instance or method): an object to extract info from.\u001b[39;00m\n\u001b[32m    644\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    645\u001b[39m     module = obj.\u001b[34m__module__\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "bands_yaml=\"./data/bands_info/bands.yaml\"\n",
    "configs_dataset=\"./data/Tiny_BigEarthNet/configs_dataset_regular.yaml\"\n",
    "config_dico = read_yaml(\"./training/configs/config_test-Atomiser_Atos.yaml\")\n",
    "#test_conf= transformations_config(config_dico,bands_yaml,configs_dataset,path_imgs_config=\"./data/Tiny_BigEarthNet/\",name_config=\"BigEarthPart\")\n",
    "#(self,configs_dataset,path_imgs_config,name_config=\"\"):\n",
    "modalities_trans= modalities_transformations_config(configs_dataset,name_config=\"regular\")\n",
    "test_conf= transformations_config(bands_yaml,config_dico)\n",
    "\n",
    "create_datasets(\"regular\",modalities_trans,trans_tokens=test_conf,sizes=(10000,10000,10000),max_len_h5=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e05cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampler initialization: 100%|██████████| 95/95 [00:00<00:00, 933158.97it/s]\n",
      "Batch creation: 100%|██████████| 3/3 [00:00<00:00, 33644.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader created on rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_module=Tiny_BigEarthNetDataModule( \"./data/Tiny_BigEarthNet/regular\", \n",
    "                                       batch_size=16, \n",
    "                                       num_workers=4,\n",
    "                                       trans_modalities=modalities_trans,\n",
    "                                       trans_tokens=test_conf,\n",
    "                                       model=\"Atomiser\")\n",
    "\n",
    "data_module.setup()\n",
    "# Prepare dataloaders\n",
    "train_loader = data_module.train_dataloader()\n",
    "#val_loader = data_module.val_dataloader()\n",
    "#test_loader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/Users/hugoriffaud/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:209: Attribute 'transform' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['transform'])`.\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/hugoriffaud/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name                            | Type                       | Params | Mode \n",
      "---------------------------------------------------------------------------------------\n",
      "0 | transform                       | transformations_config     | 0      | train\n",
      "1 | metric_train_AP_per_class       | MultilabelAveragePrecision | 0      | train\n",
      "2 | metric_train_accuracy_per_class | MultilabelAccuracy         | 0      | train\n",
      "3 | metric_val_AP_per_class         | MultilabelAveragePrecision | 0      | train\n",
      "4 | metric_val_accuracy_per_class   | MultilabelAccuracy         | 0      | train\n",
      "5 | metric_test_AP_per_class        | MultilabelAveragePrecision | 0      | train\n",
      "6 | metric_test_accuracy_per_class  | MultilabelAccuracy         | 0      | train\n",
      "7 | encoder                         | Atomiser                   | 2.1 M  | train\n",
      "8 | loss                            | BCEWithLogitsLoss          | 0      | train\n",
      "---------------------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.331     Total estimated model params size (MB)\n",
      "268       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9522f7677baf427995e5c3d5022e5e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampler initialization: 100%|██████████| 95/95 [00:00<00:00, 641640.71it/s]\n",
      "Batch creation: 100%|██████████| 3/3 [00:00<00:00, 29468.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader created on rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/hugoriffaud/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 72000, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampler initialization: 100%|██████████| 95/95 [00:00<00:00, 804967.43it/s]\n",
      "Batch creation: 100%|██████████| 3/3 [00:00<00:00, 29676.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader created on rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/hugoriffaud/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bada9da49b4dec898a0ef15fccd664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 43200, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 139968, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da30522281484081a16f44dd03c19121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 27648, 30])\n",
      "torch.Size([16, 43200, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e533f67e53d242cf9fbb7c03f8496b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 27648, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 43200, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969ba79921d24af1864424328b3c12a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 27648, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 43200, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964c294643ab4c83a7fd8f4773700f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 27648, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 43200, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 139968, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f73dfb6cb364d29874024347b4aa8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 139968, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 27648, 30])\n"
     ]
    }
   ],
   "source": [
    "xp_name=\"test_xp\"\n",
    "config_model = \"Atomiser_Atos\"\n",
    "config_name_dataset = \"tiny\"\n",
    "config_name_dataset= \"./data/custom_flair/\"+config_name_dataset\n",
    "from pytorch_lightning import Trainer,seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "config_model = read_yaml(\"./training/configs/config_test-\"+config_model+\".yaml\")\n",
    "#labels=load_json_to_dict(\"./data/flair_2_toy_dataset/flair_labels.json\")\n",
    "bands_yaml = \"./data/Tiny_BigEarthNet/bands.yaml\"\n",
    "\n",
    "bands_yaml=\"./data/bands_info/bands.yaml\"\n",
    "configs_dataset=\"./data/Tiny_BigEarthNet/configs_dataset_regular.yaml\"\n",
    "config_dico = read_yaml(\"./training/configs/config_test-Atomiser_Atos.yaml\")\n",
    "\n",
    "modalities_trans= modalities_transformations_config(configs_dataset,name_config=\"regular\")\n",
    "test_conf= transformations_config(bands_yaml,config_dico)\n",
    "\n",
    "data_module=Tiny_BigEarthNetDataModule( \"./data/Tiny_BigEarthNet/regular\", \n",
    "                                       batch_size=16, \n",
    "                                       num_workers=4,\n",
    "                                       trans_modalities=modalities_trans,\n",
    "                                       trans_tokens=test_conf,\n",
    "                                       model=\"Atomiser\")\n",
    "data_module.setup()\n",
    "# Prepare dataloaders\n",
    "\n",
    "wand = False\n",
    "wandb_logger = None\n",
    "if wand:\n",
    "    if os.environ.get(\"LOCAL_RANK\", \"0\") == \"0\":\n",
    "        import wandb\n",
    "        wandb.init(\n",
    "            name=config_model['encoder'],\n",
    "            project=config_name_dataset+\"_modalities\",\n",
    "            config=config_model\n",
    "        )\n",
    "        wandb_logger = WandbLogger(project=config_name_dataset+\"_modalities\")\n",
    "\n",
    "#def __init__(self, config, wand, name)\n",
    "model = Model(config_model,wand=wand, name=xp_name,transform=test_conf)\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_ap\", min_delta=0.00, patience=15, verbose=False, mode=\"max\")\n",
    "\n",
    "profiler = AdvancedProfiler(dirpath=\"profiling\", filename=\"profiler_output.txt\")\n",
    "\n",
    "# Configure the trainer for distributed training.\n",
    "trainer = Trainer(\n",
    "    use_distributed_sampler=False,  # we use our custom sampler\n",
    "    #strategy=\"ddp\",\n",
    "    max_epochs=config_model[\"trainer\"][\"epochs\"],\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=1,\n",
    "    #devices=1,\n",
    "    accelerator=\"gpu\",\n",
    "    callbacks=[early_stop_callback],\n",
    "    profiler=profiler  \n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=data_module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec496c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
