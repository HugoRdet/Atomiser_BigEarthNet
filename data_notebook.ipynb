{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e28fc5-b768-412c-8e0a-91aece41507a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10ec73850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from training.perceiver import*\n",
    "from training.utils import*\n",
    "from training.losses import*\n",
    "from training.VIT import*\n",
    "from training.ResNet import*\n",
    "from collections import defaultdict\n",
    "from training import*\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import einops as einops\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Reduce\n",
    "from pytorch_lightning.profilers import AdvancedProfiler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from configilm import util\n",
    "util.MESSAGE_LEVEL = util.MessageLevel.INFO  # use INFO to see all messages\n",
    "\n",
    "\n",
    "from configilm.extra.DataSets import BENv2_DataSet\n",
    "from configilm.extra.DataModules import BENv2_DataModule\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7188037a-09cf-4063-a849-c4f9c5ddb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cc97c1-2090-4da3-a929-18ff5737e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_BENv2(mode=None,max_len=None):\n",
    "    dico_paths={\"images_lmdb\":\"data/Encoded-BigEarthNet/\",\n",
    "    \"metadata_parquet\":\"data/Encoded-BigEarthNet/metadata.parquet\",\n",
    "    \"metadata_snow_cloud_parquet\":\"data/Encoded-BigEarthNet/metadata_for_patches_with_snow_cloud_or_shadow.parquet\"}\n",
    "\n",
    "    df=open_parquet(dico_paths[\"metadata_parquet\"])\n",
    "\n",
    "    if max_len!=None:\n",
    "        return BENv2_DataSet.BENv2DataSet(data_dirs=dico_paths, img_size=(14, 120, 120),split=mode,max_len=max_len),df\n",
    "\n",
    "    \n",
    "    return BENv2_DataSet.BENv2DataSet(data_dirs=dico_paths, img_size=(14, 120, 120),split=mode),df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc046e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(name,trans_conf,trans_tokens,sizes=(2,2,2),max_len=None,max_len_h5=-1):\n",
    "\n",
    "   \n",
    "    mode=\"train\"\n",
    "    ds,df=prepare_BENv2(max_len=max_len)\n",
    "\n",
    "    idxs,_=get_tiny_dataset(ds,df,MAX_IDs=sizes[0],mode=mode)\n",
    "    #idxs=None\n",
    "    stats=create_dataset(idxs, ds,df, name=name, mode=mode, trans_config=trans_conf,trans_tokens=trans_tokens,stats=None,max_len=max_len_h5)\n",
    "\n",
    "    mode=\"validation\"\n",
    "    ds,df=prepare_BENv2(max_len=max_len)\n",
    "    \n",
    "    \n",
    "    idxs,_=get_tiny_dataset(ds,df,MAX_IDs=sizes[1],mode=mode)\n",
    "    #idxs=None\n",
    "    create_dataset(idxs, ds,df, name=name, mode=mode,trans_config=trans_conf,trans_tokens=trans_tokens,stats=stats,max_len=max_len_h5)\n",
    "\n",
    "    mode=\"test\"\n",
    "    ds,_=prepare_BENv2(max_len=max_len)\n",
    "    idxs,_=get_tiny_dataset(ds,df,MAX_IDs=sizes[2],mode=mode)\n",
    "    #idxs=None\n",
    "    create_dataset(idxs, ds,df, name=name, mode=mode,trans_config=trans_conf,trans_tokens=trans_tokens,stats=stats,max_len=max_len_h5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebd737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[INFO]    Loading BEN data for None...\u001b[0m\n",
      "\u001b[96m[INFO]        480038 patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]        480038 pre-filtered patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]        480038 filtered patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]    Merged metadata with snow/cloud metadata\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded 549488 labels\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded 549488 keys\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded mapping created\u001b[0m\n",
      "\u001b[96m[INFO]    Opening LMDB environment ...\u001b[0m\n",
      "summary dico stats\n",
      "{18: 1000, 12: 1000, 8: 1000, 6: 1000, 1: 1000, 11: 1000, 15: 1000, 9: 1000, 14: 1000, 13: 1000, 3: 1000, 16: 1000, 17: 1000, 0: 1000, 5: 1000, 4: 679, 10: 1000, 7: 1000, 2: 694}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:46<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[INFO]    Loading BEN data for None...\u001b[0m\n",
      "\u001b[96m[INFO]        480038 patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]        480038 pre-filtered patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]        480038 filtered patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]    Merged metadata with snow/cloud metadata\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded 549488 labels\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded 549488 keys\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded mapping created\u001b[0m\n",
      "\u001b[96m[INFO]    Opening LMDB environment ...\u001b[0m\n",
      "summary dico stats\n",
      "{15: 1000, 12: 1000, 6: 1000, 8: 1000, 11: 1000, 18: 1000, 1: 1000, 9: 1000, 13: 1000, 5: 1000, 0: 1000, 3: 1000, 17: 1000, 16: 1000, 14: 1000, 10: 1000, 7: 1000, 4: 557, 2: 423}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:51<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m[INFO]    Loading BEN data for None...\u001b[0m\n",
      "\u001b[96m[INFO]        480038 patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]        480038 pre-filtered patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]        480038 filtered patches indexed\u001b[0m\n",
      "\u001b[96m[INFO]    Merged metadata with snow/cloud metadata\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded 549488 labels\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded 549488 keys\u001b[0m\n",
      "\u001b[96m[INFO]    Loaded mapping created\u001b[0m\n",
      "\u001b[96m[INFO]    Opening LMDB environment ...\u001b[0m\n",
      "summary dico stats\n",
      "{6: 1000, 1: 1000, 11: 1000, 12: 1000, 15: 1000, 9: 1000, 13: 1000, 8: 1000, 7: 1000, 16: 1000, 3: 1000, 17: 1000, 5: 1000, 0: 1000, 18: 1000, 10: 1000, 14: 1000, 4: 117, 2: 152}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:50<00:00,  2.65s/it]\n"
     ]
    }
   ],
   "source": [
    "bands_yaml=\"./data/bands_info/bands.yaml\"\n",
    "configs_dataset=\"./data/Tiny_BigEarthNet/configs_dataset_tiny.yaml\"\n",
    "config_dico = read_yaml(\"./training/configs/config_test-Atomiser_Atos.yaml\")\n",
    "#test_conf= transformations_config(config_dico,bands_yaml,configs_dataset,path_imgs_config=\"./data/Tiny_BigEarthNet/\",name_config=\"BigEarthPart\")\n",
    "#(self,configs_dataset,path_imgs_config,name_config=\"\"):\n",
    "modalities_trans= modalities_transformations_config(configs_dataset,name_config=\"tiny\")\n",
    "test_conf= transformations_config(bands_yaml,config_dico)\n",
    "\n",
    "#create_datasets(\"tiny\",modalities_trans,trans_tokens=test_conf,sizes=(1000,1000,1000),max_len_h5=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e05cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampler initialization: 100%|██████████| 95/95 [00:00<00:00, 933158.97it/s]\n",
      "Batch creation: 100%|██████████| 3/3 [00:00<00:00, 33644.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader created on rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_module=Tiny_BigEarthNetDataModule( \"./data/Tiny_BigEarthNet/regular\", \n",
    "                                       batch_size=16, \n",
    "                                       num_workers=4,\n",
    "                                       trans_modalities=modalities_trans,\n",
    "                                       trans_tokens=test_conf,\n",
    "                                       model=\"Atomiser\")\n",
    "\n",
    "data_module.setup()\n",
    "# Prepare dataloaders\n",
    "train_loader = data_module.train_dataloader()\n",
    "#val_loader = data_module.val_dataloader()\n",
    "#test_loader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/Users/hugoriffaud/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:209: Attribute 'transform' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['transform'])`.\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/hugoriffaud/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name                            | Type                       | Params | Mode \n",
      "---------------------------------------------------------------------------------------\n",
      "0 | transform                       | transformations_config     | 0      | train\n",
      "1 | metric_train_AP_per_class       | MultilabelAveragePrecision | 0      | train\n",
      "2 | metric_train_accuracy_per_class | MultilabelAccuracy         | 0      | train\n",
      "3 | metric_val_AP_per_class         | MultilabelAveragePrecision | 0      | train\n",
      "4 | metric_val_accuracy_per_class   | MultilabelAccuracy         | 0      | train\n",
      "5 | metric_test_AP_per_class        | MultilabelAveragePrecision | 0      | train\n",
      "6 | metric_test_accuracy_per_class  | MultilabelAccuracy         | 0      | train\n",
      "7 | encoder                         | Atomiser                   | 2.1 M  | train\n",
      "8 | loss                            | BCEWithLogitsLoss          | 0      | train\n",
      "---------------------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.331     Total estimated model params size (MB)\n",
      "268       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9522f7677baf427995e5c3d5022e5e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampler initialization: 100%|██████████| 95/95 [00:00<00:00, 641640.71it/s]\n",
      "Batch creation: 100%|██████████| 3/3 [00:00<00:00, 29468.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader created on rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/hugoriffaud/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 72000, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampler initialization: 100%|██████████| 95/95 [00:00<00:00, 804967.43it/s]\n",
      "Batch creation: 100%|██████████| 3/3 [00:00<00:00, 29676.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader created on rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/hugoriffaud/Documents/Atomiser_BigEarthNet/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bada9da49b4dec898a0ef15fccd664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 43200, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 139968, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da30522281484081a16f44dd03c19121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 27648, 30])\n",
      "torch.Size([16, 43200, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e533f67e53d242cf9fbb7c03f8496b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 27648, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 43200, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969ba79921d24af1864424328b3c12a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 27648, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 43200, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 14580, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964c294643ab4c83a7fd8f4773700f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 27648, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 43200, 30])\n",
      "torch.Size([16, 14580, 30])\n",
      "torch.Size([16, 139968, 30])\n",
      "torch.Size([16, 139968, 30])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f73dfb6cb364d29874024347b4aa8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 72000, 30])\n",
      "torch.Size([16, 139968, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 27648, 30])\n"
     ]
    }
   ],
   "source": [
    "xp_name=\"test_xp\"\n",
    "config_model = \"Atomiser_Atos\"\n",
    "config_name_dataset = \"tiny\"\n",
    "config_name_dataset= \"./data/custom_flair/\"+config_name_dataset\n",
    "from pytorch_lightning import Trainer,seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "config_model = read_yaml(\"./training/configs/config_test-\"+config_model+\".yaml\")\n",
    "#labels=load_json_to_dict(\"./data/flair_2_toy_dataset/flair_labels.json\")\n",
    "bands_yaml = \"./data/Tiny_BigEarthNet/bands.yaml\"\n",
    "\n",
    "bands_yaml=\"./data/bands_info/bands.yaml\"\n",
    "configs_dataset=\"./data/Tiny_BigEarthNet/configs_dataset_regular.yaml\"\n",
    "config_dico = read_yaml(\"./training/configs/config_test-Atomiser_Atos.yaml\")\n",
    "\n",
    "modalities_trans= modalities_transformations_config(configs_dataset,name_config=\"regular\")\n",
    "test_conf= transformations_config(bands_yaml,config_dico)\n",
    "\n",
    "data_module=Tiny_BigEarthNetDataModule( \"./data/Tiny_BigEarthNet/regular\", \n",
    "                                       batch_size=16, \n",
    "                                       num_workers=4,\n",
    "                                       trans_modalities=modalities_trans,\n",
    "                                       trans_tokens=test_conf,\n",
    "                                       model=\"Atomiser\")\n",
    "data_module.setup()\n",
    "# Prepare dataloaders\n",
    "\n",
    "wand = False\n",
    "wandb_logger = None\n",
    "if wand:\n",
    "    if os.environ.get(\"LOCAL_RANK\", \"0\") == \"0\":\n",
    "        import wandb\n",
    "        wandb.init(\n",
    "            name=config_model['encoder'],\n",
    "            project=config_name_dataset+\"_modalities\",\n",
    "            config=config_model\n",
    "        )\n",
    "        wandb_logger = WandbLogger(project=config_name_dataset+\"_modalities\")\n",
    "\n",
    "#def __init__(self, config, wand, name)\n",
    "model = Model(config_model,wand=wand, name=xp_name,transform=test_conf)\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_ap\", min_delta=0.00, patience=15, verbose=False, mode=\"max\")\n",
    "\n",
    "profiler = AdvancedProfiler(dirpath=\"profiling\", filename=\"profiler_output.txt\")\n",
    "\n",
    "# Configure the trainer for distributed training.\n",
    "trainer = Trainer(\n",
    "    use_distributed_sampler=False,  # we use our custom sampler\n",
    "    #strategy=\"ddp\",\n",
    "    max_epochs=config_model[\"trainer\"][\"epochs\"],\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=1,\n",
    "    #devices=1,\n",
    "    accelerator=\"gpu\",\n",
    "    callbacks=[early_stop_callback],\n",
    "    profiler=profiler  \n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=data_module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec496c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
